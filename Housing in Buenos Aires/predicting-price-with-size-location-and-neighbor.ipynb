{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom glob import glob\n\nimport pandas as pd\nimport seaborn as sns\nfrom category_encoders import OneHotEncoder\n# Interactive dashboard\nfrom ipywidgets import Dropdown, FloatSlider, IntSlider, interact\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge  # noqa F401\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.utils.validation import check_is_fitted\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the final lesson for this project, we're going to try to use all the features in our dataset to improve our model. This means that we'll have to do a more careful cleaning of the dataset and consider some of the finer points of linear models.","metadata":{}},{"cell_type":"markdown","source":"# Prepare Data","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.1: Use glob to create a list that contains the filenames for all the Buenos Aires real estate CSV files in the data directory. Assign this list to the variable name files","metadata":{}},{"cell_type":"code","source":"files = glob('data/buenos-aires-real-estate-*.csv')\nfiles\n#output\n['data/buenos-aires-real-estate-2.csv',\n 'data/buenos-aires-real-estate-1.csv',\n 'data/buenos-aires-real-estate-4.csv',\n 'data/buenos-aires-real-estate-5.csv',\n 'data/buenos-aires-real-estate-3.csv']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.4.2: Use your wrangle function in a list comprehension to create a list named frames. The list should contain the cleaned DataFrames for the filenames your collected in files.","metadata":{}},{"cell_type":"code","source":"frames = [wrangle(file) for file in files]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert len(frames) == 5, f\"`frames` should contain 5 items, not {len(frames)}\"\nassert all(\n    [isinstance(frame, pd.DataFrame) for frame in frames]\n), \"The items in `frames` should all be DataFrames.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Last step: Combine the DataFrames in frames into a single df.","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.3: Use pd.concat to concatenate it items in frames into a single DataFrame df. Make sure you set the ignore_index argument to True.","metadata":{}},{"cell_type":"code","source":"df = pd.concat(frames,ignore_index=True)\nprint(df.info())\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert len(df) == 6582, f\"`df` has the wrong number of rows: {len(df)}\"\nassert df.shape[1] <= 17, f\"`df` has too many columns: {df.shape[1]}\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()/ len(df)\n  # remove columns with alot of null values\n    df.drop(columns=['floor','expenses'],inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next thing we need to look out for are categorical columns with low or high cardinality. If there's only one category in a column, it won't provide any unique information to our model. At the other extreme, columns where nearly every row has its own category won't help our model in identifying useful trends in the data.","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.5: Calculate the number of unique values for each non-numeric feature in df.","metadata":{}},{"cell_type":"code","source":"df.select_dtypes(\"object\").head()\ndf.select_dtypes(\"object\").nunique\n#output\noperation           1\nproperty_type       1\ncurrency            2\nproperati_url    6582\nneighborhood       57\ndtype: int64\n# the attributes with values 1 are the low cardinality feature that u \n# have to remove from ur data \ndf.drop(columns=['operation','property_type','currency','properati_url'],inplace=True)\nadd this function to the wrangle above function","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's also important for us to drop any columns that would constitute leakage, that is, features that were created using our target or that would give our model information that it won't have access to when it's deployed.","metadata":{}},{"cell_type":"code","source":"sorted(df.columns)\n#output\n['lat',\n 'lon',\n 'neighborhood',\n #drop'price',\n #drop'price_aprox_local_currency',\n 'price_aprox_usd',\n #drop'price_per_m2',\n #drop 'price_usd_per_m2',\n 'rooms',\n 'surface_covered_in_m2',\n 'surface_total_in_m2']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert len(df) == 6582, f\"`df` has the wrong number of rows: {len(df)}\"\nassert df.shape[1] <= 7, f\"`df` has too many columns: {df.shape[1]}\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, the last issue we need to keep an eye out for is multicollinearity, that is, features in our feature matrix that are highly correlated with each other. A good way to detect this is to use a heatmap. Let's make one!","metadata":{}},{"cell_type":"code","source":"corr=df.select_dtypes(\"number\").drop(columns=\"price_aprox_usd\").corr()\nsns.heatmap(corr)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.4.9: Modify your wrangle function to remove columns so that there are no strongly correlated features in your feature matrix","metadata":{}},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.10: Create your feature matrix X_train and target vector y_train. Your target is \"price_aprox_usd\". Your features should be all the columns that remain in the DataFrame you cleaned above.","metadata":{}},{"cell_type":"code","source":"target = \"price_aprox_usd\"\ny_train=df[target]\nfeatures=[\"surface_covered_in_m2\",\"lat\",\"lon\",\"neighborhood\"]\nX_train=df[features]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert X_train.shape == (6582, 4), f\"`X_train` is the wrong size: {X_train.shape}.\"\nassert y_train.shape == (6582,), f\"`y_train` is the wrong size: {y_train.shape}.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.11: Calculate the baseline mean absolute error for your model.","metadata":{}},{"cell_type":"code","source":"y_mean=y_train.mean()\ny_pred_baseline=[y_mean]*len(y_train)\nprint(\"Mean apt price:\", round(y_mean,2))\n\nprint(\"Baseline MAE:\", mean_absolute_error(y_train,y_pred_baseline))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterate","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.12: Create a pipeline named model that contains a OneHotEncoder, SimpleImputer, and Ridge predictor.","metadata":{}},{"cell_type":"code","source":"model = make_pipeline(\n     OneHotEncoder(),\n     SimpleImputer()\n    ,Ridge()\n)\nmodel.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\ncheck_is_fitted(model[-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"markdown","source":"Task 2.4.13: Calculate the training mean absolute error for your predictions as compared to the true targets in y_train.","metadata":{}},{"cell_type":"code","source":"y_pred_training=model.predict(X_train)\nprint(\"Training MAE:\", mean_absolute_error(y_train,y_pred_training))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.4.15: Create a function make_prediction that takes four arguments (area, lat, lon, and neighborhood) and returns your model's prediction for an apartment price.","metadata":{}},{"cell_type":"code","source":"def make_prediction(area, lat, lon, neighborhood):\n    data={\n        \"surface_covered_in_m2\":area,\n        \"lat\": lat,\n        \"lon\":lon,\n        \"neighborhood\": neighborhood\n    }\n    df=pd.DataFrame(data,index=[0])\n    prediction = model.predict(df).round(2)[0]\n    return f\"Predicted apartment price: ${prediction}\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_prediction(110, -34.60, -58.46, \"Villa Crespo\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.4.16: Add your make_prediction to the interact widget below, run the cell, and then adjust the widget to see how predicted apartment price changes.","metadata":{}},{"cell_type":"code","source":"interact(\n    make_prediction,\n    area=IntSlider(\n        min=X_train[\"surface_covered_in_m2\"].min(),\n        max=X_train[\"surface_covered_in_m2\"].max(),\n        value=X_train[\"surface_covered_in_m2\"].mean(),\n    ),\n    lat=FloatSlider(\n        min=X_train[\"lat\"].min(),\n        max=X_train[\"lat\"].max(),\n        step=0.01,\n        value=X_train[\"lat\"].mean(),\n    ),\n    lon=FloatSlider(\n        min=X_train[\"lon\"].min(),\n        max=X_train[\"lon\"].max(),\n        step=0.01,\n        value=X_train[\"lon\"].mean(),\n    ),\n    neighborhood=Dropdown(options=sorted(X_train[\"neighborhood\"].unique())),\n);","metadata":{},"execution_count":null,"outputs":[]}]}