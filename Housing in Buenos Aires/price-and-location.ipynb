{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This lesson is part of the DS Lab core curriculum. For that reason, this notebook can only be used on your WQU virtual machine. That's why i didn't upload the dataset but the task followed by its answer down","metadata":{}},{"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.utils.validation import check_is_fitted\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T22:18:43.500556Z","iopub.execute_input":"2023-02-11T22:18:43.501014Z","iopub.status.idle":"2023-02-11T22:18:45.602146Z","shell.execute_reply.started":"2023-02-11T22:18:43.500925Z","shell.execute_reply":"2023-02-11T22:18:45.601163Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"In this lesson, we're going to build on the work we did in the previous lesson. We're going to create a more complex wrangle function, use it to clean more data, and build a model that considers more features when predicting apartment price.","metadata":{}},{"cell_type":"markdown","source":"# Prepare Data","metadata":{}},{"cell_type":"code","source":"def wrangle(filepath):\n    # Read CSV file\n    df = pd.read_csv(filepath)\n\n    # Subset data: Apartments in \"Capital Federal\", less than 400,000\n    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n    mask_apt = df[\"property_type\"] == \"apartment\"\n    mask_price = df[\"price_aprox_usd\"] < 400_000\n    df = df[mask_ba & mask_apt & mask_price]\n\n    # Subset data: Remove outliers for \"surface_covered_in_m2\"\n    low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n    mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n    df = df[mask_area]\n\n     #split the lat-lon column \n    df[['lat','lon']]=df['lat-lon'].str.split(',',expand=True).astype(float)\n    df.drop(columns='lat-lon',inplace=True)\n\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.1: Use your wrangle function to create a DataFrame frame1 from the CSV file data/buenos-aires-real-estate-1.csv.","metadata":{}},{"cell_type":"code","source":"frame1 = wrangle('data/buenos-aires-real-estate-1.csv')\nprint(frame1.info())\nframe1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert (\n    frame1.shape[0] == 1343\n), f\"`frame1` should have 1343 rows, not {frame1.shape[0]}.\"\nassert frame1.shape[1] == 17, f\"`frame1` should have 17 columns, not {frame1.shape[1]}.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For our model, we're going to consider apartment location, specifically, latitude and longitude. Looking at the output from frame1.info(), we can see that the location information is in a single column where the data type is object (pandas term for str in this case). In order to build our model, we need latitude and longitude to each be in their own column where the data type is float.","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.2: Add to the wrangle function below so that, in the DataFrame it returns, the \"lat-lon\" column is replaced by separate \"lat\" and \"lon\" columns. Don't forget to also drop the \"lat-lon\" column. Be sure to rerun all the cells above before you continue.","metadata":{}},{"cell_type":"code","source":" #split the lat-lon column \n    df[['lat','lon']]=df['lat-lon'].str.split(',',expand=True).astype(float)\n    df.drop(columns='lat-lon',inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.3: Use you revised wrangle function create a DataFrames frame2 from the file data/buenos-aires-real-estate-2.csv","metadata":{}},{"cell_type":"code","source":"frame2 = wrangle('data/buenos-aires-real-estate-2.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert (\n    frame2.shape[0] == 1315\n), f\"`frame1` should have 1315 rows, not {frame2.shape[0]}.\"\nassert frame2.shape[1] == 17, f\"`frame1` should have 17 columns, not {frame2.shape[1]}.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.4: Use pd.concat to concatenate frame1 and frame2 into a new DataFrame df. Make sure you set the ignore_index argument to True.","metadata":{}},{"cell_type":"code","source":"df = pd.concat([frame1,frame2],ignore_index=True)\nprint(df.info())\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert df.shape == (2658, 17), f\"`df` is the wrong size: {df.shape}\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore","metadata":{}},{"cell_type":"markdown","source":"In the last lesson, we built a simple linear model that predicted apartment price based on one feature, \"surface_covered_in_m2\". In this lesson, we're building a multiple linear regression model that predicts price based on two features, \"lon\" and \"lat\". This means that our data visualizations now have to communicate three pieces of information: Longitude, latitude, and price. How can we represent these three attributes on a two-dimensional screen?\n\nOne option is to incorporate color into our scatter plot. For example, in the Mapbox scatter plot below, the location of each point represents latitude and longitude, and color represents price.","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.5: Complete the code below to create a Mapbox scatter plot that shows the location of the apartments in df","metadata":{}},{"cell_type":"code","source":"fig = px.scatter_mapbox(\n    df,  # Our DataFrame\n    lat='lat',\n    lon='lon',\n    width=600,  # Width of map\n    height=600,  # Height of map\n    color=\"price_aprox_usd\",\n    hover_data=[\"price_aprox_usd\"],  # Display price when hovering mouse over house\n)\n\nfig.update_layout(mapbox_style=\"open-street-map\")\n\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another option is to add a third dimension to our scatter plot. We can plot longitude on the x-axis and latitude on the y-axis (like we do in the map above), and then add a z-axis with price.","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.6: Complete the code below to create a 3D scatter plot, with \"lon\" on the x-axis, \"lat\" on the y-axis, and \"price_aprox_usd\" on the z-axis.","metadata":{}},{"cell_type":"code","source":"# Create 3D scatter plot\nfig = px.scatter_3d(\n    df,\n    x=\"lon\",\n    y=\"lat\",\n    z=\"price_aprox_usd\",\n    labels={\"lon\": \"longitude\", \"lat\": \"latitude\", \"price_aprox_usd\": \"price\"},\n    width=600,\n    height=500,\n)\n\n# Refine formatting\nfig.update_traces(\n    marker={\"size\": 4, \"line\": {\"width\": 2, \"color\": \"DarkSlateGrey\"}},\n    selector={\"mode\": \"markers\"},\n)\n\n# Display figure\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"markdown","source":"Even though we're building a different model, the steps we follow will be the same. Let's separate our features (latitude and longitude) from our target (price).","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.7: Create the feature matrix named X_train. It should contain two features: [\"lon\", \"lat\"]","metadata":{}},{"cell_type":"code","source":"features = [\"lon\", \"lat\"]\nX_train = df[features]\nX_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.8: Create the target vector named y_train, which you'll use to train your model. Your target should be \"price_aprox_usd\". Remember that, in most cases, your target vector should be one-dimensional.","metadata":{}},{"cell_type":"code","source":"target = \"price_aprox_usd\"\ny_train = df[target]\ny_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"****Baseline****\n\nAgain, we need to set a baseline so we can evaluate our model's performance. You'll notice that the value of y_mean is not exactly the same as it was in the previous lesson. That's because we've added more observations to our training data.","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.9: Calculate the mean of your target vector y_train and assign it to the variable y_mean.","metadata":{}},{"cell_type":"code","source":"y_mean = y_train.mean()\ny_mean\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.10: Create a list named y_pred_baseline that contains the value of y_mean repeated so that it's the same length at y_train.","metadata":{}},{"cell_type":"code","source":"y_pred_baseline = [y_mean]*len(y_train)\ny_pred_baseline[:5]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.11: Calculate the baseline mean absolute error for your predictions in y_pred_baseline as compared to the true targets in y_train.","metadata":{}},{"cell_type":"code","source":"mae_baseline = mean_absolute_error(y_train,y_pred_baseline)\n\nprint(\"Mean apt price\", round(y_mean, 2))\nprint(\"Baseline MAE:\", round(mae_baseline, 2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterate","metadata":{}},{"cell_type":"markdown","source":"Take a moment to scroll up to the output for df.info() and look at the values in the \"Non-Null Count\" column. Because of the math it uses, a linear regression model can't handle observations where there are missing values. Do you see any columns where this will be a problem?\n\nIn the last project, we simply dropped rows that contained NaN values, but this isn't ideal. Models generally perform better when they have more data to train with, so every row is precious. Instead, we can fill in these missing values using information we get from the whole column — a process called imputation. There are many different strategies for imputing missing values, and one of the most common is filling in the missing values with the mean of the column.\n\nIn addition to predictors like LinearRegression, scikit-learn also has transformers that help us deal with issues like missing values. Let's see how one works, and then we'll add it to our model.","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.12: Instantiate a SimpleImputer named imputer.","metadata":{}},{"cell_type":"code","source":"imputer = SimpleImputer ()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert isinstance(imputer, SimpleImputer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just like a predictor, a transformer has a fit method. In the case of our SimpleImputer, this is the step where it calculates the mean values for each numerical column.","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.13: Fit your transformer imputer to the feature matrix X.","metadata":{}},{"cell_type":"code","source":"imputer.fit(X_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\ncheck_is_fitted(imputer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.14: Use your imputer to transform the feature matrix X_train. Assign the transformed data to the variable XT_train.","metadata":{}},{"cell_type":"code","source":"XT_train = imputer.transform(X_train)\npd.DataFrame(XT_train, columns=X_train.columns).info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert XT_train.shape == (2658, 2), f\"`XT_train` is the wrong shape: {XT_train.shape}\"\nassert (\n    np.isnan(XT_train).sum() == 0\n), \"Your feature matrix still has `NaN` values. Did you forget to transform is using `imputer`?\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay! Our data is free of missing values, and we have a good sense for how predictors work in scikit-learn. However, the truth is you'll rarely do data transformations this way. Why? A model may require multiple transformers, and doing all those transformations one-by-one is slow and likely to lead to errors. 🤦‍♀️ Instead, we can combine our transformer and predictor into a single object called a pipeline","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.15: Create a pipeline named model that contains a SimpleImputer transformer followed by a LinearRegression predictor.","metadata":{}},{"cell_type":"code","source":"model = make_pipeline(\n     SimpleImputer(),\n     LinearRegression()\n     \n\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert isinstance(model, Pipeline), \"Did you instantiate your model?\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.16: Fit your model to the data, X_train and y_train.","metadata":{}},{"cell_type":"code","source":"model.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\ncheck_is_fitted(model[\"linearregression\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evalute","metadata":{}},{"cell_type":"markdown","source":"As always, we'll start by evaluating our model's performance on the training data","metadata":{}},{"cell_type":"markdown","source":"Task 2.2.17: Using your model's predict method, create a list of predictions for the observations in your feature matrix X_train. Name this list y_pred_training.","metadata":{}},{"cell_type":"code","source":"y_pred_training = model.predict(X_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert y_pred_training.shape == (2658,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.18: Calculate the training mean absolute error for your predictions in y_pred_training as compared to the true targets in y_train.","metadata":{}},{"cell_type":"code","source":"mae_training = mean_absolute_error(y_train,y_pred_training)\nprint(\"Training MAE:\", round(mae_training, 2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training MAE: 42962.72\nIt looks like our model performs a little better than the baseline. This suggests that latitude and longitude aren't as strong predictors of price as size is.\n\nNow let's check our test performance. Remember, once we test our model, there's no more iteration allowed.","metadata":{}},{"cell_type":"markdown","source":"# Communicate Results","metadata":{}},{"cell_type":"markdown","source":"Let's take a look at the equation our model has come up with for predicting price based on latitude and longitude. We'll need to expand on our formula to account for both features.\n\nEquation: y = beta 0 + beta 1 * x","metadata":{}},{"cell_type":"code","source":"Task 2.2.20: Extract the intercept and coefficients for your model.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intercept = model.named_steps['linearregression'].intercept_.round()\ncoefficients = model.named_steps['linearregression'].coef_.round()\nintercept , coefficients","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.21: Complete the code below and run the cell to print the equation that your model has determined for predicting apartment price based on latitude and longitude","metadata":{}},{"cell_type":"code","source":"print(\n    \n    f\"price = {intercept } + ({coefficients[0]} * longitude) + ({coefficients[1]} * latitude)\"\n)\n# price = 38113587.0 + (196709.0 * longitude) + (765467.0 * latitude)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.2.22: Complete the code below to create a 3D scatter plot, with \"lon\" on the x-axis, \"lat\" on the y-axis, and \"price_aprox_usd\" on the z-axis.","metadata":{}},{"cell_type":"code","source":"# Create 3D scatter plot\nfig = px.scatter_3d(\n    df,\n    x=\"lon\",\n    y=\"lat\",\n    z=\"price_aprox_usd\",\n    labels={\"lon\": \"longitude\", \"lat\": \"latitude\", \"price_aprox_usd\": \"price\"},\n    width=600,\n    height=500,\n)\n\n# Create x and y coordinates for model representation\nx_plane = np.linspace(df[\"lon\"].min(), df[\"lon\"].max(), 10)\ny_plane = np.linspace(df[\"lat\"].min(), df[\"lat\"].max(), 10)\nxx, yy = np.meshgrid(x_plane, y_plane)\n\n# Use model to predict z coordinates\nz_plane = model.predict(pd.DataFrame({\"lon\": x_plane, \"lat\": y_plane}))\nzz = np.tile(z_plane, (10, 1))\n\n# Add plane to figure\nfig.add_trace(go.Surface(x=xx, y=yy, z=zz))\n\n# Refine formatting\nfig.update_traces(\n    marker={\"size\": 4, \"line\": {\"width\": 2, \"color\": \"DarkSlateGrey\"}},\n    selector={\"mode\": \"markers\"},\n)\n\n# Display figure\nfig.show()","metadata":{},"execution_count":null,"outputs":[]}]}