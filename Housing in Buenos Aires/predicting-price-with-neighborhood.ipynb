{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-12T19:28:19.532645Z","iopub.execute_input":"2023-02-12T19:28:19.533559Z","iopub.status.idle":"2023-02-12T19:28:19.563944Z","shell.execute_reply.started":"2023-02-12T19:28:19.533431Z","shell.execute_reply":"2023-02-12T19:28:19.562578Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom category_encoders import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression, Ridge  # noqa F401\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.utils.validation import check_is_fitted\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"In the last lesson, we created a model that used location — \nrepresented by latitude and longitude — to predict price. \nIn this lesson, we're going to use a different representation for \nlocation: neighborhood.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.1: Use glob to create a list that contains the filenames for all the Buenos Aires real estate CSV files in the data directory. Assign this list to the variable name files.","metadata":{}},{"cell_type":"code","source":"files = glob(\"data/buenos-aires-real-estate-*.csv\")\nfiles","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert len(files) == 5, f\"`files` should contain 5 items, not {len(files)}\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.2: Use your wrangle function in a for loop to create a list named frames. The list should the cleaned DataFrames created from the CSV filenames your collected in files.","metadata":{}},{"cell_type":"code","source":"frames = []\nfor file in files:\n    df=wrangle(file)\n    frames.append(df)\n\nlen(frames)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert len(frames) == 5, f\"`frames` should contain 5 items, not {len(frames)}\"\nassert all(\n    [isinstance(frame, pd.DataFrame) for frame in frames]\n), \"The items in `frames` should all be DataFrames.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.3: Use pd.concat to concatenate the items in frames into a single DataFrame df. Make sure you set the ignore_index argument to True","metadata":{}},{"cell_type":"code","source":"df = pd.concat(frames,ignore_index=True)\ndf.head()\ndf.shape\n(6582, 17)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert len(df) == 6582, f\"`df` is the wrong size: {len(df)}.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore","metadata":{}},{"cell_type":"markdown","source":"Looking through the output from the df.head() call above, there's a little bit more cleaning we need to do before we can work with the neighborhood information in this dataset. The good news is that, because we're using a wrangle function, we only need to change the function to re-clean all of our CSV files. This is why functions are so useful.","metadata":{}},{"cell_type":"markdown","source":"Task 2.3.4: Modify your wrangle function to create a new feature \"neighborhood\". You can find the neighborhood for each property in the \"place_with_parent_names\" column. For example, a property with the place name \"|Argentina|Capital Federal|Palermo|\" is located in the neighborhood is \"Palermo\". Also, your function should drop the \"place_with_parent_names\" column.\n\nBe sure to rerun all the cells above before you continue.","metadata":{}},{"cell_type":"code","source":"def wrangle(filepath):\n    # Read CSV file\n    df = pd.read_csv(filepath)\n\n    # Subset data: Apartments in \"Capital Federal\", less than 400,000\n    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n    mask_apt = df[\"property_type\"] == \"apartment\"\n    mask_price = df[\"price_aprox_usd\"] < 400_000\n    df = df[mask_ba & mask_apt & mask_price]\n\n    # Subset data: Remove outliers for \"surface_covered_in_m2\"\n    low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n    mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n    df = df[mask_area]\n\n    # Split \"lat-lon\" column\n    df[[\"lat\", \"lon\"]] = df[\"lat-lon\"].str.split(\",\", expand=True).astype(float)\n    df.drop(columns=\"lat-lon\", inplace=True)\n    # Extract neighborhood\n    df['neighborhood']=df['place_with_parent_names'].str.split('|',expand=True)[3]\n    df.drop(columns='place_with_parent_names',inplace=True)\n\n    \n\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"target = \"price_aprox_usd\"\nfeatures = [\"neighborhood\"]\ny_train = df[target]\nX_train = df[features]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert X_train.shape == (6582, 1), f\"`X_train` is the wrong size: {X_train.shape}.\"\nassert y_train.shape == (6582,), f\"`y_train` is the wrong size: {y_train.shape}.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"Task 2.3.6: Calculate the baseline mean absolute error for your model.","metadata":{}},{"cell_type":"code","source":"y_mean = y_train.mean()\ny_pred_baseline = [y_mean]* len(y_train)\nprint(\"Mean apt price:\", y_mean)\n\nprint(\"Baseline MAE:\", mean_absolute_error(y_train,y_pred_baseline))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterate","metadata":{}},{"cell_type":"markdown","source":"Task 2.3.7: First, instantiate a OneHotEncoder named ohe. Make sure to set the use_cat_names argument to True. Next, fit your transformer to the feature matrix X_train. Finally, use your encoder to transform the feature matrix X_train, and assign the transformed data to the variable XT_train.","metadata":{}},{"cell_type":"code","source":"ohe = OneHotEncoder(use_cat_names=True)\nohe.fit(X_train)\nXT_train =ohe.transform(X_train)\nprint(XT_train.shape)\nXT_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have an idea for how the OneHotEncoder works, let's bring it into our pipeline.","metadata":{}},{"cell_type":"markdown","source":"Task 2.3.8: Create a pipeline named model that contains a OneHotEncoder transformer and a LinearRegression predictor. Then fit your model to the training data.","metadata":{}},{"cell_type":"code","source":"model = make_pipeline(\n     OneHotEncoder(use_cat_names=True)\n    ,LinearRegression()\n)\nmodel.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\ncheck_is_fitted(model[-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"markdown","source":"Task 2.3.9: First, create a list of predictions for the observations in your feature matrix X_train. Name this list y_pred_training. Then calculate the training mean absolute error for your predictions in y_pred_training as compared to the true targets in y_train.","metadata":{}},{"cell_type":"code","source":"y_pred_training = model.predict(X_train)\nmae_training = mean_absolute_error(y_train,y_pred_training)\nprint(\"Training MAE:\", round(mae_training, 2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Task 2.3.11: Extract the intercept and coefficients for your model.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intercept = model.named_steps['linearregression'].intercept_\ncoefficients = model.named_steps['linearregression'].coef_\nprint(\"coefficients len:\", len(coefficients))\nprint(coefficients[:5])  # First five coefficients","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert isinstance(\n    intercept, float\n), f\"`intercept` should be a `float`, not {type(intercept)}.\"\nassert isinstance(\n    coefficients, np.ndarray\n), f\"`coefficients` should be a `float`, not {type(coefficients)}.\"\nassert coefficients.shape == (\n    57,\n), f\"`coefficients` is wrong shape: {coefficients.shape}.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.12: Extract the feature names of your encoded data from the OneHotEncoder in your model.","metadata":{}},{"cell_type":"code","source":"feature_names = model.named_steps['onehotencoder'].get_feature_names()\nprint(\"features len:\", len(feature_names))\nprint(feature_names[:5])  # First five feature names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert isinstance(\n    feature_names, list\n), f\"`features` should be a `list`, not {type(features)}.\"\nassert len(feature_names) == len(\n    coefficients\n), \"You should have the same number of features and coefficients.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.13: Create a pandas Series named feat_imp where the index is your features and the values are your coefficients","metadata":{}},{"cell_type":"code","source":"feat_imp = pd.Series(coefficients,index=feature_names)\nfeat_imp.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#neighborhood_Recoleta            6.157563e+17\n#neighborhood_Monserrat           6.157563e+17\n#neighborhood_Belgrano            6.157563e+17\n#neighborhood_Villa del Parque    6.157563e+17\n#neighborhood_Villa Pueyrredón    6.157563e+17\n#dtype: float64","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your work\nassert isinstance(\n    feat_imp, pd.Series\n), f\"`feat_imp` should be a `float`, not {type(feat_imp)}.\"\nassert feat_imp.shape == (57,), f\"`feat_imp` is wrong shape: {feat_imp.shape}.\"\nassert all(\n    a == b for a, b in zip(sorted(feature_names), sorted(feat_imp.index))\n), \"The index of `feat_imp` should be identical to `features`.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.14: Run the cell below to print the equation that your model has determined for predicting apartment price based on longitude and latitude.","metadata":{}},{"cell_type":"code","source":"print(f\"price = {intercept.round(2)}\")\nfor f, c in feat_imp.items():\n    print(f\"+ ({round(c, 2)} * {f})\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"price = -6.157563196756461e+17\n+ (6.157563196758367e+17 * neighborhood_Recoleta)\n+ (6.157563196757453e+17 * neighborhood_Monserrat)\n+ (6.157563196758118e+17 * neighborhood_Belgrano)\n+ (6.157563196757504e+17 * neighborhood_Villa del Parque)\n+ (6.157563196757568e+17 * neighborhood_Villa Pueyrredón)\n+ (6.15756319675768e+17 * neighborhood_Almagro)\n+ (6.15756319675812e+17 * neighborhood_Palermo)\n+ (6.157563196757443e+17 * neighborhood_)\n+ (6.157563196757554e+17 * neighborhood_Tribunales)\n+ (6.157563196757522e+17 * neighborhood_Balvanera)\n+ (6.157563196758194e+17 * neighborhood_Barrio Norte)\n+ (6.157563196757608e+17 * neighborhood_Once)\n+ (6.157563196757691e+17 * neighborhood_San Telmo)\n+ (6.157563196757146e+17 * neighborhood_Villa Lugano)\n+ (6.157563196757763e+17 * neighborhood_Coghlan)\n+ (6.157563196757583e+17 * neighborhood_Barracas)\n+ (6.157563196757773e+17 * neighborhood_Villa Urquiza)\n+ (6.15756319675769e+17 * neighborhood_Abasto)\n+ (6.157563196757709e+17 * neighborhood_Villa Crespo)\n+ (6.157563196757437e+17 * neighborhood_Villa Santa Rita)\n+ (6.157563196758024e+17 * neighborhood_Colegiales)\n+ (6.157563196757573e+17 * neighborhood_Paternal)\n+ (6.157563196757725e+17 * neighborhood_Caballito)\n+ (6.157563196757573e+17 * neighborhood_Parque Chacabuco)\n+ (6.157563196757921e+17 * neighborhood_Retiro)\n+ (6.157563196757686e+17 * neighborhood_Villa Devoto)\n+ (6.157563196757644e+17 * neighborhood_Villa Luro)\n+ (6.157563196757533e+17 * neighborhood_San Nicolás)\n+ (6.157563196757787e+17 * neighborhood_Saavedra)\n+ (6.157563196757559e+17 * neighborhood_Flores)\n+ (6.157563196757564e+17 * neighborhood_Centro / Microcentro)\n+ (6.157563196757508e+17 * neighborhood_Liniers)\n+ (6.15756319675753e+17 * neighborhood_San Cristobal)\n+ (6.157563196757359e+17 * neighborhood_Boca)\n+ (6.157563196757568e+17 * neighborhood_Congreso)\n+ (6.157563196757583e+17 * neighborhood_Parque Centenario)\n+ (6.157563196757299e+17 * neighborhood_Parque Chas)\n+ (6.157563196758076e+17 * neighborhood_Nuñez)\n+ (6.157563196757482e+17 * neighborhood_Parque Patricios)\n+ (6.157563196757573e+17 * neighborhood_Boedo)\n+ (6.157563196757496e+17 * neighborhood_Floresta)\n+ (6.157563196757427e+17 * neighborhood_Mataderos)\n+ (6.157563196758956e+17 * neighborhood_Puerto Madero)\n+ (6.157563196757732e+17 * neighborhood_Villa General Mitre)\n+ (6.157563196757637e+17 * neighborhood_Agronomía)\n+ (6.15756319675753e+17 * neighborhood_Villa Ortuzar)\n+ (6.157563196757614e+17 * neighborhood_Chacarita)\n+ (6.157563196757316e+17 * neighborhood_Velez Sarsfield)\n+ (6.157563196757606e+17 * neighborhood_Monte Castro)\n+ (6.157563196758394e+17 * neighborhood_Las Cañitas)\n+ (6.157563196757217e+17 * neighborhood_Constitución)\n+ (6.157563196757329e+17 * neighborhood_Parque Avellaneda)\n+ (6.15756319675691e+17 * neighborhood_Villa Soldati)\n+ (6.157563196757588e+17 * neighborhood_Versalles)\n+ (6.157563196757551e+17 * neighborhood_Villa Real)\n+ (6.157563196757124e+17 * neighborhood_Pompeya)\n+ (6.157563196757211e+17 * neighborhood_Catalinas)","metadata":{}},{"cell_type":"code","source":"what happening above is called curse of dimensionality\nto solved use Ridge() model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.15: Scroll up, change the predictor in your model to Ridge, and retrain it. Then evaluate the model's training and test performance. Do you still have an overfitting problem? If not, extract the intercept and coefficients again (you'll need to change your code a little bit) and regenerate the model's equation. Does it look different than before?","metadata":{}},{"cell_type":"code","source":"model = make_pipeline(\n     OneHotEncoder(use_cat_names=True)\n    ,Ridge()\n)\nmodel.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2.3.16: Create a horizontal bar chart that shows the top 15 coefficients for your model, based on their absolute value.","metadata":{}},{"cell_type":"code","source":"feat_imp.sort_values(key=abs).tail(15).plot(kind=\"barh\")\nplt.xlabel(\"Importance [USD]\")\nplt.ylabel(\"Feature\")\nplt.title(\"Feature Importance for Apartment Price\")","metadata":{},"execution_count":null,"outputs":[]}]}